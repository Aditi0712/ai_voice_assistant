{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aditi0712/ai_voice_assistant/blob/main/ai_voice_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tiktoken cohere kaleido openai ffmpeg openai-whisper gradio torch transformers"
      ],
      "metadata": {
        "id": "diPX5QSG4m8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "import whisper\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "UZkihRIbMuR-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openaikey=userdata.get('openai')"
      ],
      "metadata": {
        "id": "ZdCORUbCkblx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI( api_key=openaikey)"
      ],
      "metadata": {
        "id": "41wUmZChDX6k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr_model = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBRbPwuWAA68",
        "outputId": "97071a79-b4a9-47d0-baaa-65a701c2ee94"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chat_reponse(transcribed_msg):\n",
        "  completion = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a kind and helpful assistant who answers to to the questions in a fun way.\"},\n",
        "                {\"role\": \"user\", \"content\": transcribed_msg}\n",
        "            ]\n",
        "        )\n",
        "  reply=completion.choices[0].message.content\n",
        "  return reply"
      ],
      "metadata": {
        "id": "ZeL1WtNEqDe4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio_input(audio):\n",
        "    sr, y = audio\n",
        "    y = y.astype(np.float32)\n",
        "    y /= np.max(np.abs(y))\n",
        "    result=asr_model({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
        "    return result"
      ],
      "metadata": {
        "id": "DM-IvDaOD0pf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(audio_input):\n",
        "  transcribed_msg=transcribe_audio_input(audio_input)\n",
        "  response=chat_reponse(transcribed_msg)\n",
        "  return response"
      ],
      "metadata": {
        "id": "V88Eec1rIDnx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# q=\"What is capital of India?\"\n",
        "# res=chat_reponse(q)\n",
        "# res"
      ],
      "metadata": {
        "id": "VhZ3uJANXN-W"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reply=gr.Textbox(label=\"Generated Response\")\n",
        "audio_input=gr.Audio(sources=[\"microphone\"])\n",
        "gr.Interface(\n",
        "    title='AI Voice Assistant',\n",
        "    fn=generate_response,\n",
        "    inputs=[audio_input],\n",
        "    outputs=[reply],\n",
        "    live=True\n",
        ").launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "cvssVAgQYBzD",
        "outputId": "ef1f347b-e7d9-4851-ad72-6d1231277222"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://ab6b229ccd9e4c8a9a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ab6b229ccd9e4c8a9a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://ab6b229ccd9e4c8a9a.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}